{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Unlock the power of Natural Language Processing (NLP) by diving into Kaggle competitions! In this tutorial, I will cover essential NLP concepts, explore real-world datasets, and walk you through your first competition. Whether youâ€™re a beginner or curious about NLP, this tutorial will kickstart your journey. ðŸš€","metadata":{}},{"cell_type":"markdown","source":"This tutorial is heavily inspired by a bunch of other resources and all the credit goes to them (all the resources can be found at the end of this notebook). This tutorial is my attempt to learn something new as well as help you to learn.","metadata":{}},{"cell_type":"markdown","source":"## The data\nWe are going to use the data from this competition - [\"Natural Language Processing with Disaster Tweets\"](https://www.kaggle.com/competitions/nlp-getting-started). Kaggle hosts some \"getting started\" competitions which are easy enough for beginners to learn the tricks of the trade and challenging enough to practice different ML concepts. This is one such competiion where you can learn as you work through it.\n\nDownload the data by visiting the competition page or if you are working in kaggle notebook then you can attach this data to your notebook by following the steps mentioned [here](https://www.kaggle.com/docs/notebooks).","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T06:29:22.738978Z","iopub.execute_input":"2024-04-19T06:29:22.739832Z","iopub.status.idle":"2024-04-19T06:29:23.746658Z","shell.execute_reply.started":"2024-04-19T06:29:22.739797Z","shell.execute_reply":"2024-04-19T06:29:23.745890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset has three files - \n* submission.csv - is a sample file to let you know what your submission should look like.\n* train.csv - this is the data on which you would need to train your model.\n* test.csv - this is the data on which you have to do the predictions after you have done the training.","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/nlp-getting-started/train.csv\"\neval_path = \"/kaggle/input/nlp-getting-started/test.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.748386Z","iopub.execute_input":"2024-04-19T06:29:23.749176Z","iopub.status.idle":"2024-04-19T06:29:23.753599Z","shell.execute_reply.started":"2024-04-19T06:29:23.749141Z","shell.execute_reply":"2024-04-19T06:29:23.752717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we will use pandas to read the data.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\neval_df = pd.read_csv(eval_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.754979Z","iopub.execute_input":"2024-04-19T06:29:23.755800Z","iopub.status.idle":"2024-04-19T06:29:23.839355Z","shell.execute_reply.started":"2024-04-19T06:29:23.755768Z","shell.execute_reply":"2024-04-19T06:29:23.838566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5) ","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.841348Z","iopub.execute_input":"2024-04-19T06:29:23.841618Z","iopub.status.idle":"2024-04-19T06:29:23.858798Z","shell.execute_reply.started":"2024-04-19T06:29:23.841595Z","shell.execute_reply":"2024-04-19T06:29:23.857989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.859867Z","iopub.execute_input":"2024-04-19T06:29:23.860137Z","iopub.status.idle":"2024-04-19T06:29:23.869789Z","shell.execute_reply.started":"2024-04-19T06:29:23.860115Z","shell.execute_reply":"2024-04-19T06:29:23.868775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the data\nYou can use the describe method in pandas to get a quick look into what your dataset looks like. For example, here you can see the most common keywords in the data is \"fatalities\" and most common location is \"USA\".","metadata":{}},{"cell_type":"code","source":"train_df.describe(include=\"object\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.871009Z","iopub.execute_input":"2024-04-19T06:29:23.871690Z","iopub.status.idle":"2024-04-19T06:29:23.904361Z","shell.execute_reply.started":"2024-04-19T06:29:23.871659Z","shell.execute_reply":"2024-04-19T06:29:23.903553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature engineering\nWe can join the keyword, location and text to create a meanigful string that contains the information of the keyword and location as well. There are some keywords and location which doesn't have anything for this first we will put N/A for these cells. \n\nYou can use other strategies to take care of the rows which have Nan value for some columns but don't entirely remove them because removign them will remove important datapoints.","metadata":{}},{"cell_type":"markdown","source":"`fillna` fills the given value in all the cells which are Nan.","metadata":{}},{"cell_type":"code","source":"train_df = train_df.fillna(\"N/A\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.905348Z","iopub.execute_input":"2024-04-19T06:29:23.905595Z","iopub.status.idle":"2024-04-19T06:29:23.912985Z","shell.execute_reply.started":"2024-04-19T06:29:23.905574Z","shell.execute_reply":"2024-04-19T06:29:23.912024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.914354Z","iopub.execute_input":"2024-04-19T06:29:23.915119Z","iopub.status.idle":"2024-04-19T06:29:23.929564Z","shell.execute_reply.started":"2024-04-19T06:29:23.915084Z","shell.execute_reply":"2024-04-19T06:29:23.928572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"you can concatenate the values of multiple rows using the plus(+) operator. ","metadata":{}},{"cell_type":"code","source":"train_df['input'] = 'keyword: ' + train_df.keyword + '; location: ' + train_df.location + '; text: ' + train_df.text","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.930778Z","iopub.execute_input":"2024-04-19T06:29:23.931070Z","iopub.status.idle":"2024-04-19T06:29:23.945691Z","shell.execute_reply.started":"2024-04-19T06:29:23.931049Z","shell.execute_reply":"2024-04-19T06:29:23.944846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.949807Z","iopub.execute_input":"2024-04-19T06:29:23.950038Z","iopub.status.idle":"2024-04-19T06:29:23.961788Z","shell.execute_reply.started":"2024-04-19T06:29:23.950018Z","shell.execute_reply":"2024-04-19T06:29:23.960959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert the dataframe to huggingface dataset. Doing this helps in making the dataframe much more easier and faster to work.","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset,DatasetDict\ndataset = Dataset.from_pandas(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:23.962664Z","iopub.execute_input":"2024-04-19T06:29:23.962944Z","iopub.status.idle":"2024-04-19T06:29:25.206349Z","shell.execute_reply.started":"2024-04-19T06:29:23.962923Z","shell.execute_reply":"2024-04-19T06:29:25.205503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:25.207677Z","iopub.execute_input":"2024-04-19T06:29:25.208256Z","iopub.status.idle":"2024-04-19T06:29:25.214520Z","shell.execute_reply.started":"2024-04-19T06:29:25.208218Z","shell.execute_reply":"2024-04-19T06:29:25.213664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The model\nSince we are wexperimenting at this point, we can select a model which is small enough to run quickly. For this I have selected the below model which has good balance of size and performance.\n\nOnce you progerss with your experiments and have evaluated your model's performance, you can opt for more complex models.","metadata":{}},{"cell_type":"code","source":"model_name = 'microsoft/deberta-v3-small'","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:25.215769Z","iopub.execute_input":"2024-04-19T06:29:25.216026Z","iopub.status.idle":"2024-04-19T06:29:25.223364Z","shell.execute_reply.started":"2024-04-19T06:29:25.216004Z","shell.execute_reply":"2024-04-19T06:29:25.222486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization\nNeural networks don't understand texts, they understand numbers. Before feeding data we need to break the text into words and then convert those to numbers. Breaking text to words is known as tokenization and converting the words to numbers is known as numericalization.","metadata":{}},{"cell_type":"markdown","source":"Huggingface provides a `AutoTokenizer` API to tokenize text. This also numericalizes the tokens into numbers.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:25.224570Z","iopub.execute_input":"2024-04-19T06:29:25.225279Z","iopub.status.idle":"2024-04-19T06:29:34.004048Z","shell.execute_reply.started":"2024-04-19T06:29:25.225211Z","shell.execute_reply":"2024-04-19T06:29:34.003185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create a function which can use this tokenizer to tokenize a text.","metadata":{}},{"cell_type":"code","source":"test_tokz = tokenizer.tokenize(\"hello! have a good day\")\ntest_tokz","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:34.005098Z","iopub.execute_input":"2024-04-19T06:29:34.005543Z","iopub.status.idle":"2024-04-19T06:29:34.011914Z","shell.execute_reply.started":"2024-04-19T06:29:34.005518Z","shell.execute_reply":"2024-04-19T06:29:34.011014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look how the tokenizer breaks down the text into words. An underscore is added to the begining of the words to represents the start of a word. ","metadata":{}},{"cell_type":"markdown","source":"Let's create a function to tokenize the text.","metadata":{}},{"cell_type":"code","source":"def tokz(df):\n    return tokenizer(df[\"input\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:34.012965Z","iopub.execute_input":"2024-04-19T06:29:34.013235Z","iopub.status.idle":"2024-04-19T06:29:34.022460Z","shell.execute_reply.started":"2024-04-19T06:29:34.013212Z","shell.execute_reply":"2024-04-19T06:29:34.021643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the `map` function takes our function and applies it to the entire dataset.","metadata":{}},{"cell_type":"code","source":"dataset = dataset.map(tokz)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:34.023625Z","iopub.execute_input":"2024-04-19T06:29:34.024636Z","iopub.status.idle":"2024-04-19T06:29:37.219560Z","shell.execute_reply.started":"2024-04-19T06:29:34.024605Z","shell.execute_reply":"2024-04-19T06:29:37.218634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:37.220784Z","iopub.execute_input":"2024-04-19T06:29:37.221081Z","iopub.status.idle":"2024-04-19T06:29:37.230873Z","shell.execute_reply.started":"2024-04-19T06:29:37.221055Z","shell.execute_reply":"2024-04-19T06:29:37.229960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"A new column 'input_ids' is added to our datset. These have some numbers and each of these numbers are index to the words which are in the list that the tokenizer maintains internally. \n\nActually the tokenizer object that huggingface's `tokenizer` API pulls maintains a list of every possible word. We can find which word is at what index like this.","metadata":{}},{"cell_type":"code","source":"tokenizer.vocab['Forest']","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:37.232070Z","iopub.execute_input":"2024-04-19T06:29:37.232390Z","iopub.status.idle":"2024-04-19T06:29:37.331978Z","shell.execute_reply.started":"2024-04-19T06:29:37.232362Z","shell.execute_reply":"2024-04-19T06:29:37.330994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the data for training ","metadata":{}},{"cell_type":"markdown","source":"Transformers expect the target column to be named as \"labels\".","metadata":{}},{"cell_type":"code","source":"dataset = dataset.rename_column(\"target\", \"label\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:37.333088Z","iopub.execute_input":"2024-04-19T06:29:37.333416Z","iopub.status.idle":"2024-04-19T06:29:37.343907Z","shell.execute_reply.started":"2024-04-19T06:29:37.333391Z","shell.execute_reply":"2024-04-19T06:29:37.343089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:37.344959Z","iopub.execute_input":"2024-04-19T06:29:37.345199Z","iopub.status.idle":"2024-04-19T06:29:37.355078Z","shell.execute_reply.started":"2024-04-19T06:29:37.345179Z","shell.execute_reply":"2024-04-19T06:29:37.354177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting data into Train and test\nNext we will split the data into train and test. This is required to prevent the following problems-\n\n* Generalization: By testing on unseen data, you assess how well your model generalizes beyond the training data. It ensures that your model doesnâ€™t just memorize the training examples but learns meaningful patterns.\n\n* Overfitting Prevention: If you train and test the model on the same data (without splitting), it can lead to overfitting. Overfit models perform well on the training data but fail to generalize to new instances. Train-test split helps prevent this issue.\n\n* Bias-Variance Tradeoff: It also helps you understand the bias-variance tradeoff. A model with high bias (underfitting) may perform poorly on both training and testing data, while a model with high variance (overfitting) may perform well on training data but poorly on testing data","metadata":{}},{"cell_type":"markdown","source":"we reserve 25% of our training data as the validation set. this will be hidden from the model during training and then an evaluation of the model's prediction will be done on this part of the data at the end of each epoch.","metadata":{}},{"cell_type":"code","source":"train_test = dataset.train_test_split(test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:37.356144Z","iopub.execute_input":"2024-04-19T06:29:37.356431Z","iopub.status.idle":"2024-04-19T06:29:37.376553Z","shell.execute_reply.started":"2024-04-19T06:29:37.356409Z","shell.execute_reply":"2024-04-19T06:29:37.375868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:37.377599Z","iopub.execute_input":"2024-04-19T06:29:37.377939Z","iopub.status.idle":"2024-04-19T06:29:37.383752Z","shell.execute_reply.started":"2024-04-19T06:29:37.377909Z","shell.execute_reply":"2024-04-19T06:29:37.382873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"it is always a goodd idea to look into the data and then decide your splitting strategy. splitting like we did above is not recomended but for the sake of this tutorial we are fine.","metadata":{}},{"cell_type":"markdown","source":"## Evaluation\nThe competition page describes the evaluation metric which is going to be used in the competition. Here they are going to use a metric known as the F1 metric. You can check the competition [page](https://www.kaggle.com/competitions/nlp-getting-started) for a detailed description of the metric.","metadata":{}},{"cell_type":"markdown","source":"We will need to create a function which will take our predictions and then calculate the metric for us. For this we will make use of the scikitlearn library which is a popular library for machine learnign tasks other than deep learning.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n\n    f1 = f1_score(labels, preds, average='weighted')\n\n    return {'f1': f1}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:37.385006Z","iopub.execute_input":"2024-04-19T06:29:37.385327Z","iopub.status.idle":"2024-04-19T06:29:38.609154Z","shell.execute_reply.started":"2024-04-19T06:29:37.385298Z","shell.execute_reply":"2024-04-19T06:29:38.608308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning the model\nThe model which we are going to use is already trained on loads of english text. However, it's unaware of the tweet data on which we want to make predictions. That is why we will fine tune the model on our data.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:38.610316Z","iopub.execute_input":"2024-04-19T06:29:38.610805Z","iopub.status.idle":"2024-04-19T06:29:41.972855Z","shell.execute_reply.started":"2024-04-19T06:29:38.610780Z","shell.execute_reply":"2024-04-19T06:29:41.972028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will pass our data in a batch of 128 and keep a low epoch to train quickly. Keep the learning rate as given below, it will work just fine for a wide range of situations. \n\nThe learning rate is one of the most important hyperparameter. A bad learning rate can ruin your trained model's performance.\n\nWatch this [lesson](https://course18.fast.ai/lessonsml1/lesson9.html) from the awsome fastai course to understand the importance of learning rate.","metadata":{}},{"cell_type":"code","source":"bs = 128\nepochs = 4\nlr = 8e-5","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:41.974175Z","iopub.execute_input":"2024-04-19T06:29:41.974696Z","iopub.status.idle":"2024-04-19T06:29:41.978953Z","shell.execute_reply.started":"2024-04-19T06:29:41.974669Z","shell.execute_reply":"2024-04-19T06:29:41.977934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the hugging face trainer requires you to set model arguments via the `TrainingArguments` object. don't worry about all the arguments as the important arguments are the ones listed above.","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:41.980126Z","iopub.execute_input":"2024-04-19T06:29:41.980441Z","iopub.status.idle":"2024-04-19T06:29:52.838817Z","shell.execute_reply.started":"2024-04-19T06:29:41.980406Z","shell.execute_reply":"2024-04-19T06:29:52.837768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we begin our training and pass the our metric computation function to it.","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_test[\"train\"], \n    eval_dataset=train_test[\"test\"],   \n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:52.844392Z","iopub.execute_input":"2024-04-19T06:29:52.844680Z","iopub.status.idle":"2024-04-19T06:29:53.152340Z","shell.execute_reply.started":"2024-04-19T06:29:52.844657Z","shell.execute_reply":"2024-04-19T06:29:53.151503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:29:53.153500Z","iopub.execute_input":"2024-04-19T06:29:53.153793Z","iopub.status.idle":"2024-04-19T06:32:00.534977Z","shell.execute_reply.started":"2024-04-19T06:29:53.153768Z","shell.execute_reply":"2024-04-19T06:32:00.533760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the f1 score is showing a good increase.","metadata":{}},{"cell_type":"markdown","source":"as I explained earlier that kaggle competitions provide a test set as well on which we need to carry out predictions after our model is trained. These predictions will then be submitted to the compeition.","metadata":{}},{"cell_type":"markdown","source":"## Preparing the test data\nWe will do the same transformation to the test data as well.","metadata":{}},{"cell_type":"code","source":"eval_df = eval_df.fillna(\"N/A\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:00.536752Z","iopub.execute_input":"2024-04-19T06:32:00.538313Z","iopub.status.idle":"2024-04-19T06:32:00.547209Z","shell.execute_reply.started":"2024-04-19T06:32:00.538279Z","shell.execute_reply":"2024-04-19T06:32:00.546112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df['input'] = 'keyword: ' + eval_df.keyword + '; location: ' + eval_df.location + '; text: ' + eval_df.text","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:00.548566Z","iopub.execute_input":"2024-04-19T06:32:00.549147Z","iopub.status.idle":"2024-04-19T06:32:00.567169Z","shell.execute_reply.started":"2024-04-19T06:32:00.549114Z","shell.execute_reply":"2024-04-19T06:32:00.566048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:00.568895Z","iopub.execute_input":"2024-04-19T06:32:00.569387Z","iopub.status.idle":"2024-04-19T06:32:00.582031Z","shell.execute_reply.started":"2024-04-19T06:32:00.569359Z","shell.execute_reply":"2024-04-19T06:32:00.581148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_ds = dataset.from_pandas(eval_df).map(tokz)\neval_ds","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:00.583040Z","iopub.execute_input":"2024-04-19T06:32:00.583314Z","iopub.status.idle":"2024-04-19T06:32:01.896195Z","shell.execute_reply.started":"2024-04-19T06:32:00.583291Z","shell.execute_reply":"2024-04-19T06:32:01.895263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_ds[1][\"input\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:01.897283Z","iopub.execute_input":"2024-04-19T06:32:01.897563Z","iopub.status.idle":"2024-04-19T06:32:01.903760Z","shell.execute_reply.started":"2024-04-19T06:32:01.897539Z","shell.execute_reply":"2024-04-19T06:32:01.902777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submitting Predictions","metadata":{}},{"cell_type":"markdown","source":"We can use the trainer object to carry out the predictions.","metadata":{}},{"cell_type":"code","source":"preds = trainer.predict(eval_ds).predictions.astype(float)\npreds","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:01.904909Z","iopub.execute_input":"2024-04-19T06:32:01.905169Z","iopub.status.idle":"2024-04-19T06:32:07.332439Z","shell.execute_reply.started":"2024-04-19T06:32:01.905148Z","shell.execute_reply":"2024-04-19T06:32:07.331530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npredictions = np.argmax(preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:07.333642Z","iopub.execute_input":"2024-04-19T06:32:07.333955Z","iopub.status.idle":"2024-04-19T06:32:07.338502Z","shell.execute_reply.started":"2024-04-19T06:32:07.333929Z","shell.execute_reply":"2024-04-19T06:32:07.337537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:07.339634Z","iopub.execute_input":"2024-04-19T06:32:07.339988Z","iopub.status.idle":"2024-04-19T06:32:07.355523Z","shell.execute_reply.started":"2024-04-19T06:32:07.339965Z","shell.execute_reply":"2024-04-19T06:32:07.354738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"finally we will create the submission.csv file and this is what we are going to submit to the competition.","metadata":{}},{"cell_type":"code","source":"submission = Dataset.from_dict({\n    'id': eval_ds['id'],\n    'target': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:32:07.356541Z","iopub.execute_input":"2024-04-19T06:32:07.356818Z","iopub.status.idle":"2024-04-19T06:32:07.409856Z","shell.execute_reply.started":"2024-04-19T06:32:07.356796Z","shell.execute_reply":"2024-04-19T06:32:07.408850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\n* https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners\n* https://course.fast.ai/Lessons/lesson4.html\n* https://huggingface.co/learn/nlp-course/chapter1/1","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}